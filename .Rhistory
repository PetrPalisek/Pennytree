post_state <- alpha * beta
post_state <- post_state / rowSums(post_state)
# Expected transitions (for updating gamma)
xi_sum <- matrix(0, N, N)
for (s in seq_along(seg_starts)) {
a <- seg_starts[s]; b <- seg_ends[s]
if (a < b) {
for (t in a:(b - 1)) {
# outer over states: alpha_t(i) * gamma(i,j) * allprobs_{t+1}(j) * beta_{t+1}(j)
numer <- (alpha[t, ] %o% (allprobs[t + 1, ] * beta[t + 1, ])) * gamma
denom <- sum(numer)
if (denom > 0) xi_sum <- xi_sum + numer / denom
}
}
}
# M-step: update gamma (row-normalize) & delta (stationary or data-driven)
gamma_next <- xi_sum / pmax(rowSums(xi_sum), .Machine$double.eps)
if (stationary) {
A <- t(diag(N) - t(gamma_next))
A[N, ] <- 1
bvec <- c(rep(0, N - 1), 1)
delta_next <- as.vector(solve(A, bvec))
} else {
# average initial state posteriors at segment starts
starts_mat <- matrix(FALSE, nrow = Ttot, ncol = 1); starts_mat[seg_starts] <- TRUE
delta_next <- colMeans(post_state[starts_mat[,1], , drop = FALSE])
delta_next <- delta_next / sum(delta_next)
}
# Refit trees with responsibilities as weights
tmp <- fit_trees_and_emissions(post_state)
mods <- tmp$mods
allprobs <- tmp$allprobs
# Convergence check
if (verbose) cat(sprintf("Iter %d | logLik = %.3f\r", iter, llh))
if (abs(llh - old_ll) < conv_tol) {
if (verbose) cat(sprintf("\nConverged at iter %d | logLik = %.3f\n", iter, llh))
break
}
if (iter == max_iter && verbose) {
cat(sprintf("\nStopped at max_iter=%d | logLik = %.3f\n", max_iter, llh))
}
old_ll <- llh
gamma  <- gamma_next
delta  <- delta_next
weights <- post_state
}
list(
mod = mods,                 # list of rpart trees (one per state)
delta = delta,              # initial state distribution
gamma = gamma,              # transition matrix
llh = old_ll,               # final log-likelihood
state_probs = weights,      # T x N posterior P(state | data)
N = N,
resp_levels = resp_levels,
id_col = id_col,
formula = formula,
control = list(minbucket = minbucket, cp = cp)
)
}
fit_msdt <- function(
data,
N = 2,
formula = response ~ type + ratio,  # your given formula
id_col = "participant_id",          # sequence boundary column
minbucket = 100,
cp = 0.001,
max_iter = 1000,
conv_tol = 1e-3,
stationary = TRUE,                  # delta as stationary of gamma
verbose = TRUE,
seed = 123
) {
# ---- dependencies ----
if (!requireNamespace("rpart", quietly = TRUE)) stop("Please install.packages('rpart')")
stopifnot(N >= 2)
set.seed(seed)
# ---- Basic checks & preparation ------------------------------------------
if (!all(all.vars(formula) %in% names(data))) {
stop("Data is missing variables in the formula.")
}
if (!id_col %in% names(data)) {
stop("id_col not found in data.")
}
dat <- data
# Ensure binary factor response
resp_name <- all.vars(update(formula, . ~ 1))[1]
dat[[resp_name]] <- if (is.factor(dat[[resp_name]])) dat[[resp_name]] else factor(dat[[resp_name]])
if (nlevels(dat[[resp_name]]) != 2) stop("This function expects a binary response with 2 levels.")
resp_levels <- levels(dat[[resp_name]])
# Ensure ordering within id (if you have an explicit trial order, pre-arrange before calling)
dat <- dat[order(dat[[id_col]]), , drop = FALSE]
Ttot <- nrow(dat)
# Sequence lengths to reset HMM at boundaries
rle_ids    <- rle(as.character(dat[[id_col]]))
seg_lengths <- rle_ids$lengths
seg_starts  <- cumsum(c(1, head(seg_lengths, -1)))
seg_ends    <- cumsum(seg_lengths)
# ---- Initialize transition & initial state probabilities ------------------
gamma <- matrix(0, N, N)
diag(gamma) <- 0.95
gamma[gamma == 0] <- (1 - 0.95) / (N - 1)
if (stationary) {
# stationary distribution of gamma
A <- t(diag(N) - t(gamma))
A[N, ] <- 1
b <- c(rep(0, N - 1), 1)
delta <- as.vector(solve(A, b))
} else {
delta <- rep(1 / N, N)
}
# ---- Initialize responsibilities (weights) for tree fits -----------------
weights <- matrix(runif(Ttot * N), nrow = Ttot, ncol = N)
weights <- weights / rowSums(weights)
# ---- Helper: fit N trees & compute emission probabilities ----------------
# allprobs: T x N with allprobs[t, i] = P(y_t | state=i) for the observed class
fit_trees_and_emissions <- function(wts) {
mods <- vector("list", N)
allprobs <- matrix(NA_real_, nrow = Ttot, ncol = N)
# index of observed class per row (column position in predict(..., type='prob'))
# will compute per-state after prediction since column names can differ
for (i in seq_len(N)) {
# rpart evaluates weights inside the data env; add a temp column it can see
tmp_dat <- dat
tmp_dat$.__w <- as.numeric(wts[, i])
mods[[i]] <- rpart::rpart(
formula,
data   = tmp_dat,
weights = .__w,
method = "class",
control = rpart::rpart.control(minbucket = minbucket, cp = cp, xval = 0)
)
pr <- predict(mods[[i]], newdata = dat, type = "prob")  # T x 2 (levels may be ordered)
# Map each row to the prob of its observed class:
obs_idx <- match(dat[[resp_name]], colnames(pr))        # length T
allprobs[, i] <- pr[cbind(seq_len(Ttot), obs_idx)]
# Numerical guard
allprobs[, i] <- pmax(allprobs[, i], .Machine$double.eps)
}
list(mods = mods, allprobs = allprobs)
}
# Initial M-step with random weights
tmp <- fit_trees_and_emissions(weights)
mods <- tmp$mods
allprobs <- tmp$allprobs
# ---- EM loop --------------------------------------------------------------
old_ll <- -Inf
for (iter in seq_len(max_iter)) {
# E-step: Forward-Backward with scaling, per segment
alpha <- matrix(0, nrow = Ttot, ncol = N)
beta  <- matrix(0, nrow = Ttot, ncol = N)
cfac  <- rep(1, Ttot)
llh   <- 0
# Forward
for (s in seq_along(seg_starts)) {
a <- seg_starts[s]; b <- seg_ends[s]
# t = a
alpha[a, ] <- delta * allprobs[a, ]
cfac[a]    <- sum(alpha[a, ])
alpha[a, ] <- alpha[a, ] / cfac[a]
# t = a+1..b
if (a < b) {
for (t in (a + 1):b) {
alpha[t, ] <- (alpha[t - 1, ] %*% gamma) * allprobs[t, ]
cfac[t]    <- sum(alpha[t, ])
alpha[t, ] <- alpha[t, ] / cfac[t]
}
}
llh <- llh + sum(log(cfac[a:b]))
}
# Backward
for (s in seq_along(seg_starts)) {
a <- seg_starts[s]; b <- seg_ends[s]
beta[b, ] <- 1 / cfac[b]
if (a < b) {
for (t in (b - 1):a) {
beta[t, ] <- (gamma %*% (allprobs[t + 1, ] * beta[t + 1, ]))
beta[t, ] <- beta[t, ] / cfac[t]
}
}
}
# Posterior state probs
post_state <- alpha * beta
post_state <- post_state / rowSums(post_state)
# Expected transitions for gamma update
xi_sum <- matrix(0, N, N)
for (s in seq_along(seg_starts)) {
a <- seg_starts[s]; b <- seg_ends[s]
if (a < b) {
for (t in a:(b - 1)) {
numer <- (alpha[t, ] %o% (allprobs[t + 1, ] * beta[t + 1, ])) * gamma
denom <- sum(numer)
if (denom > 0) xi_sum <- xi_sum + numer / denom
}
}
}
# M-step: update gamma & delta
gamma_next <- xi_sum / pmax(rowSums(xi_sum), .Machine$double.eps)
if (stationary) {
A <- t(diag(N) - t(gamma_next))
A[N, ] <- 1
bvec <- c(rep(0, N - 1), 1)
delta_next <- as.vector(solve(A, bvec))
} else {
# average initial posteriors at segment starts
starts_idx <- rep(FALSE, Ttot); starts_idx[seg_starts] <- TRUE
delta_next <- colMeans(post_state[starts_idx, , drop = FALSE])
delta_next <- delta_next / sum(delta_next)
}
# Refit trees with new responsibilities
tmp <- fit_trees_and_emissions(post_state)
mods <- tmp$mods
allprobs <- tmp$allprobs
# Convergence
if (verbose) cat(sprintf("Iter %d | logLik = %.3f\r", iter, llh))
if (abs(llh - old_ll) < conv_tol) {
if (verbose) cat(sprintf("\nConverged at iter %d | logLik = %.3f\n", iter, llh))
old_ll <- llh
gamma  <- gamma_next
delta  <- delta_next
weights <- post_state
break
}
if (iter == max_iter && verbose) {
cat(sprintf("\nStopped at max_iter=%d | logLik = %.3f\n", max_iter, llh))
}
old_ll <- llh
gamma  <- gamma_next
delta  <- delta_next
weights <- post_state
}
list(
mod = mods,                 # list of rpart trees (one per state)
delta = delta,              # initial state distribution
gamma = gamma,              # transition matrix
llh = old_ll,               # final (scaled) log-likelihood
state_probs = weights,      # T x N posterior P(state | data)
N = N,
resp_levels = resp_levels,
id_col = id_col,
formula = formula,
control = list(minbucket = minbucket, cp = cp)
)
}
fit_msdt <- function(
data,
N = 2,
formula = response ~ type + ratio,  # your given formula
id_col = "participant_id",          # sequence boundary column
minbucket = 100,
cp = 0.001,
max_iter = 1000,
conv_tol = 1e-3,
stationary = TRUE,                  # delta as stationary of gamma
verbose = TRUE,
seed = 123
) {
# ---- dependencies ----
if (!requireNamespace("rpart", quietly = TRUE)) stop("Please install.packages('rpart')")
stopifnot(N >= 2)
set.seed(seed)
# ---- Basic checks & preparation ------------------------------------------
if (!all(all.vars(formula) %in% names(data))) {
stop("Data is missing variables in the formula.")
}
if (!id_col %in% names(data)) {
stop("id_col not found in data.")
}
dat <- data
# Ensure binary factor response
resp_name <- all.vars(update(formula, . ~ 1))[1]
dat[[resp_name]] <- if (is.factor(dat[[resp_name]])) dat[[resp_name]] else factor(dat[[resp_name]])
if (nlevels(dat[[resp_name]]) != 2) stop("This function expects a binary response with 2 levels.")
resp_levels <- levels(dat[[resp_name]])
# Ensure ordering within id (if you have an explicit trial order, pre-arrange before calling)
dat <- dat[order(dat[[id_col]]), , drop = FALSE]
Ttot <- nrow(dat)
# Sequence lengths to reset HMM at boundaries
rle_ids    <- rle(as.character(dat[[id_col]]))
seg_lengths <- rle_ids$lengths
seg_starts  <- cumsum(c(1, head(seg_lengths, -1)))
seg_ends    <- cumsum(seg_lengths)
# ---- Initialize transition & initial state probabilities ------------------
gamma <- matrix(0, N, N)
diag(gamma) <- 0.95
gamma[gamma == 0] <- (1 - 0.95) / (N - 1)
if (stationary) {
# stationary distribution of gamma
A <- t(diag(N) - t(gamma))
A[N, ] <- 1
b <- c(rep(0, N - 1), 1)
delta <- as.vector(solve(A, b))
} else {
delta <- rep(1 / N, N)
}
# ---- Initialize responsibilities (weights) for tree fits -----------------
weights <- matrix(runif(Ttot * N), nrow = Ttot, ncol = N)
weights <- weights / rowSums(weights)
# ---- Helper: fit N trees & compute emission probabilities ----------------
# allprobs: T x N with allprobs[t, i] = P(y_t | state=i) for the observed class
fit_trees_and_emissions <- function(wts) {
mods <- vector("list", N)
allprobs <- matrix(NA_real_, nrow = Ttot, ncol = N)
# index of observed class per row (column position in predict(..., type='prob'))
# will compute per-state after prediction since column names can differ
for (i in seq_len(N)) {
# rpart evaluates weights inside the data env; add a temp column it can see
tmp_dat <- dat
tmp_dat$.__w <- as.numeric(wts[, i])
mods[[i]] <- rpart::rpart(
formula,
data   = tmp_dat,
weights = .__w,
method = "class",
control = rpart::rpart.control(minbucket = minbucket, cp = cp, xval = 0)
)
pr <- predict(mods[[i]], newdata = dat, type = "prob")  # T x 2 (levels may be ordered)
# Map each row to the prob of its observed class:
obs_idx <- match(dat[[resp_name]], colnames(pr))        # length T
allprobs[, i] <- pr[cbind(seq_len(Ttot), obs_idx)]
# Numerical guard
allprobs[, i] <- pmax(allprobs[, i], .Machine$double.eps)
}
list(mods = mods, allprobs = allprobs)
}
# Initial M-step with random weights
tmp <- fit_trees_and_emissions(weights)
mods <- tmp$mods
allprobs <- tmp$allprobs
# ---- EM loop --------------------------------------------------------------
old_ll <- -Inf
for (iter in seq_len(max_iter)) {
# E-step: Forward-Backward with scaling, per segment
alpha <- matrix(0, nrow = Ttot, ncol = N)
beta  <- matrix(0, nrow = Ttot, ncol = N)
cfac  <- rep(1, Ttot)
llh   <- 0
# Forward
for (s in seq_along(seg_starts)) {
a <- seg_starts[s]; b <- seg_ends[s]
# t = a
alpha[a, ] <- delta * allprobs[a, ]
cfac[a]    <- sum(alpha[a, ])
alpha[a, ] <- alpha[a, ] / cfac[a]
# t = a+1..b
if (a < b) {
for (t in (a + 1):b) {
alpha[t, ] <- (alpha[t - 1, ] %*% gamma) * allprobs[t, ]
cfac[t]    <- sum(alpha[t, ])
alpha[t, ] <- alpha[t, ] / cfac[t]
}
}
llh <- llh + sum(log(cfac[a:b]))
}
# Backward
for (s in seq_along(seg_starts)) {
a <- seg_starts[s]; b <- seg_ends[s]
beta[b, ] <- 1 / cfac[b]
if (a < b) {
for (t in (b - 1):a) {
beta[t, ] <- (gamma %*% (allprobs[t + 1, ] * beta[t + 1, ]))
beta[t, ] <- beta[t, ] / cfac[t]
}
}
}
# Posterior state probs
post_state <- alpha * beta
post_state <- post_state / rowSums(post_state)
# Expected transitions for gamma update
xi_sum <- matrix(0, N, N)
for (s in seq_along(seg_starts)) {
a <- seg_starts[s]; b <- seg_ends[s]
if (a < b) {
for (t in a:(b - 1)) {
numer <- (alpha[t, ] %o% (allprobs[t + 1, ] * beta[t + 1, ])) * gamma
denom <- sum(numer)
if (denom > 0) xi_sum <- xi_sum + numer / denom
}
}
}
# M-step: update gamma & delta
gamma_next <- xi_sum / pmax(rowSums(xi_sum), .Machine$double.eps)
if (stationary) {
A <- t(diag(N) - t(gamma_next))
A[N, ] <- 1
bvec <- c(rep(0, N - 1), 1)
delta_next <- as.vector(solve(A, bvec))
} else {
# average initial posteriors at segment starts
starts_idx <- rep(FALSE, Ttot); starts_idx[seg_starts] <- TRUE
delta_next <- colMeans(post_state[starts_idx, , drop = FALSE])
delta_next <- delta_next / sum(delta_next)
}
# Refit trees with new responsibilities
tmp <- fit_trees_and_emissions(post_state)
mods <- tmp$mods
allprobs <- tmp$allprobs
# Convergence
if (verbose) cat(sprintf("Iter %d | logLik = %.3f\r", iter, llh))
if (abs(llh - old_ll) < conv_tol) {
if (verbose) cat(sprintf("\nConverged at iter %d | logLik = %.3f\n", iter, llh))
old_ll <- llh
gamma  <- gamma_next
delta  <- delta_next
weights <- post_state
break
}
if (iter == max_iter && verbose) {
cat(sprintf("\nStopped at max_iter=%d | logLik = %.3f\n", max_iter, llh))
}
old_ll <- llh
gamma  <- gamma_next
delta  <- delta_next
weights <- post_state
}
list(
mod = mods,                 # list of rpart trees (one per state)
delta = delta,              # initial state distribution
gamma = gamma,              # transition matrix
llh = old_ll,               # final (scaled) log-likelihood
state_probs = weights,      # T x N posterior P(state | data)
N = N,
resp_levels = resp_levels,
id_col = id_col,
formula = formula,
control = list(minbucket = minbucket, cp = cp)
)
}
fit <- fit_msdt(
data    = df,
N       = 3,
formula = response ~ type + ratio,
id_col  = "participant_id",
minbucket = 50, cp = 0.001, max_iter = 500, conv_tol = 1e-3
)
fit <- fit_msdt(
data    = df,
N       = 3,
formula = response ~ type + ratio,
id_col  = "participant_id",
minbucket = 50, cp = 0.001, max_iter = 500, conv_tol = 1e-3
state_hat <- max.col(fit$state_probs)           # 1..N
fit <- fit_msdt(
data    = df,
N       = 3,
formula = response ~ type + ratio,
id_col  = "participant_id",
minbucket = 50, cp = 0.001, max_iter = 500, conv_tol = 1e-3
state_hat <- max.col(fit$state_probs)           # 1..N
state_hat <- max.col(fit$state_probs)           # 1..N
df$hmm_state <- factor(state_hat, levels = 1:fit$N)
# Inspect trees per state
fit$mod[[1]]
fit$mod[[2]]
fit$mod[[3]]
# Inspect trees per state
fit$mod[[1]] %>% plot()
# Inspect trees per state
fit$mod[[1]] %>% rpart.plot()
fit$mod[[2]] %>% rpart.plot()
fit$mod[[3]] %>% rpart.plot()
summary(fit)
state_hat <- max.col(fit$state_probs)           # 1..N
state_hat
fit$gamma
fit$gamma %>% round(2)
# ── 3) Global (pooled) decision tree & plot ────────────────────────────────
# Predict response from type and ratio across all participants
tree_all <- rpart(
response ~  type + ratio,
data   = df,
method = "class",
control = rpart.control(minsplit = 10, cp = 0.001, xval = 10)
)
rpart.rules(tree_all)
# ── 3) Global (pooled) decision tree & plot ────────────────────────────────
# Predict response from type and ratio across all participants
tree_all <- rpart(
response ~  type + ratio,
data   = df,
method = "class",
control = rpart.control(minsplit = 10, cp = 0.001, xval = 10, maxdepth = 3)
)
rpart.rules(tree_all)
# ── 3) Global (pooled) decision tree & plot ────────────────────────────────
# Predict response from type and ratio across all participants
tree_all <- rpart(
response ~  type + ratio,
data   = df,
method = "class",
control = rpart.control(minsplit = 10, cp = 0.001, xval = 10, maxdepth = 4)
)
rpart.rules(tree_all)
df
View(df)
?rpart
# ── 3) Global (pooled) decision tree & plot ────────────────────────────────
# Predict response from type and ratio across all participants
tree_all <- rpart(
rt ~  type + ratio ,
data   = df,
method = "anova",
control = rpart.control(minsplit = 10, cp = 0.001, xval = 10, maxdepth = 4)
)
# ── 3) Global (pooled) decision tree & plot ────────────────────────────────
# Predict response from type and ratio across all participants
tree_all <- rpart(
rt ~  type + ratio ,
data   = df,
method = "anova",
control = rpart.control(minsplit = 10, cp = 0.001, xval = 10)
)
rpart.plot(tree_all)
